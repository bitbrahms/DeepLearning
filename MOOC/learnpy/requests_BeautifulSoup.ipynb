{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('https://github.com/timeline.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"message\":\"Hello there, wayfaring stranger. If you’re reading this then you probably didn’t see our blog post a couple of years back announcing that this API would go away: http://git.io/17AROg Fear not, you should be able to get what you need from the shiny new Events API instead.\",\"documentation_url\":\"https://developer.github.com/v3/activity/events/#list-public-events\"}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf-8\n"
     ]
    }
   ],
   "source": [
    "print(r.encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "payload = {'key1':'value1','key2':'value2'}\n",
    "r = requests.get('http://httpbin.org/get',params=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://httpbin.org/get?key1=value1&key2=value2\n"
     ]
    }
   ],
   "source": [
    "print(r.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "payload = {'key1':'value1','key2':['value2', 'value3']}\n",
    "r = requests.get('http://httpbin.org/get',params=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://httpbin.org/get?key1=value1&key2=value2&key2=value3\n"
     ]
    }
   ],
   "source": [
    "print(r.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"message\":\"Hello there, wayfaring stranger. If you\\xe2\\x80\\x99re reading this then you probably didn\\xe2\\x80\\x99t see our blog post a couple of years back announcing that this API would go away: http://git.io/17AROg Fear not, you should be able to get what you need from the shiny new Events API instead.\",\"documentation_url\":\"https://developer.github.com/v3/activity/events/#list-public-events\"}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x065AABA0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-15e652c4f8ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2517\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2518\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[1;32m-> 2519\u001b[1;33m                   % (filename if filename else fp))\n\u001b[0m\u001b[0;32m   2520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2521\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x065AABA0>"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "i = Image.open(BytesIO(r.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documentation_url': 'https://developer.github.com/v3/activity/events/#list-public-events',\n",
       " 'message': 'Hello there, wayfaring stranger. If you’re reading this then you probably didn’t see our blog post a couple of years back announcing that this API would go away: http://git.io/17AROg Fear not, you should be able to get what you need from the shiny new Events API instead.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<head>\n",
    "      <meta charset=\"utf-8\">\n",
    "      <meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\">\n",
    "    <title>首页 - 简书</title>\n",
    "</head>\n",
    "\n",
    "<body class=\"output fluid zh cn win reader-day-mode reader-font2 \" data-js-module=\"recommendation\" data-locale=\"zh-CN\">\n",
    "\n",
    "<ul class=\"article-list thumbnails\">\n",
    "\n",
    "  <li class=have-img>\n",
    "      <a class=\"wrap-img\" href=\"/p/49c4728c3ab2\"><img src=\"http://upload-images.jianshu.io/upload_images/2442470-745c6471c6f8258c.jpg?imageMogr2/auto-orient/strip%7CimageView2/1/w/300/h/300\" alt=\"300\" /></a>\n",
    "    <div>\n",
    "      <p class=\"list-top\">\n",
    "        <a class=\"author-name blue-link\" target=\"_blank\" href=\"/users/0af6b163b687\">阿随向前冲</a>\n",
    "        <em>·</em>\n",
    "        <span class=\"time\" data-shared-at=\"2016-07-27T07:03:54+08:00\"></span>\n",
    "      </p>\n",
    "      <h4 class=\"title\"><a target=\"_blank\" href=\"/p/49c4728c3ab2\"> 只装了这六款软件，工作就高效到有时间逛某宝刷某圈</a></h4>\n",
    "      <div class=\"list-footer\">\n",
    "        <a target=\"_blank\" href=\"/p/49c4728c3ab2\">\n",
    "          阅读 1830\n",
    "</a>        <a target=\"_blank\" href=\"/p/49c4728c3ab2#comments\">\n",
    "           · 评论 35\n",
    "</a>        <span> · 喜欢 95</span>\n",
    "          <span> · 打赏 1</span>\n",
    "\n",
    "      </div>\n",
    "    </div>\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "</body>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:146: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_doc, 'html.parser', from_encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = soup.find_all('li', class_='have-img')\n",
    "for tag in tags:\n",
    "    image = tag.img('src')\n",
    "    article_user = tag.p.a.get_text()\n",
    "    article_user_url = tag.p.a['href']\n",
    "    created = tag.p.span['data-shared-at']\n",
    "    article_url = tag.h4.a['href']\n",
    "    tag_span = tag.div.div.find_all('span')\n",
    "    likes = tag_span[0].get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"wrap-img\" href=\"/p/49c4728c3ab2\"><img alt=\"300\" src=\"http://upload-images.jianshu.io/upload_images/2442470-745c6471c6f8258c.jpg?imageMogr2/auto-orient/strip%7CimageView2/1/w/300/h/300\"/></a>,\n",
       " <a class=\"author-name blue-link\" href=\"/users/0af6b163b687\" target=\"_blank\">阿随向前冲</a>,\n",
       " <a href=\"/p/49c4728c3ab2\" target=\"_blank\"> 只装了这六款软件，工作就高效到有时间逛某宝刷某圈</a>,\n",
       " <a href=\"/p/49c4728c3ab2\" target=\"_blank\">\n",
       "           阅读 1830\n",
       " </a>,\n",
       " <a href=\"/p/49c4728c3ab2#comments\" target=\"_blank\">\n",
       "            · 评论 35\n",
       " </a>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')\n",
    "soup('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'阿随向前冲'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.p.a.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\" name=\"dromouse\"><b>The Dormouse's story</b></p>\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\"><!-- Elsie --></a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\workspace\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\" name=\"dromouse\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    <!-- Elsie -->\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title>The Dormouse's story</title></head>\n"
     ]
    }
   ],
   "source": [
    "print(soup.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>\n"
     ]
    }
   ],
   "source": [
    "print(soup.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "print(type(soup.a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[document]\n"
     ]
    }
   ],
   "source": [
    "print(soup.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n"
     ]
    }
   ],
   "source": [
    "print(soup.head.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"title\" name=\"dromouse\"><b>The Dormouse's story</b></p>\n"
     ]
    }
   ],
   "source": [
    "print(soup.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': ['title'], 'name': 'dromouse'}\n"
     ]
    }
   ],
   "source": [
    "print(soup.p.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title']\n"
     ]
    }
   ],
   "source": [
    "print(soup.p['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"newclass\" name=\"dromouse\"><b>The Dormouse's story</b></p>\n"
     ]
    }
   ],
   "source": [
    "soup.p['class'] = 'newclass'\n",
    "print(soup.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del soup.p['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p name=\"dromouse\"><b>The Dormouse's story</b></p>\n"
     ]
    }
   ],
   "source": [
    "print(soup.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "print(soup.p.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Elsie \n"
     ]
    }
   ],
   "source": [
    "print(soup.a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.NavigableString'>\n"
     ]
    }
   ],
   "source": [
    "print(type(soup.p.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>\n"
     ]
    }
   ],
   "source": [
    "print(soup.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Elsie \n"
     ]
    }
   ],
   "source": [
    "print(soup.a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Comment'>\n"
     ]
    }
   ],
   "source": [
    "print(type(soup.a.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if type(soup.a.string) == 'bs4.element.Comment':\n",
    "    print(soup.a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package bs4:\n",
      "\n",
      "NAME\n",
      "    bs4\n",
      "\n",
      "DESCRIPTION\n",
      "    Beautiful Soup\n",
      "    Elixir and Tonic\n",
      "    \"The Screen-Scraper's Friend\"\n",
      "    http://www.crummy.com/software/BeautifulSoup/\n",
      "    \n",
      "    Beautiful Soup uses a pluggable XML or HTML parser to parse a\n",
      "    (possibly invalid) document into a tree representation. Beautiful Soup\n",
      "    provides methods and Pythonic idioms that make it easy to navigate,\n",
      "    search, and modify the parse tree.\n",
      "    \n",
      "    Beautiful Soup works with Python 2.7 and up. It works better if lxml\n",
      "    and/or html5lib is installed.\n",
      "    \n",
      "    For more than you ever wanted to know about Beautiful Soup, see the\n",
      "    documentation:\n",
      "    http://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    builder (package)\n",
      "    dammit\n",
      "    diagnose\n",
      "    element\n",
      "    testing\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    bs4.element.Tag(bs4.element.PageElement)\n",
      "        BeautifulSoup\n",
      "    \n",
      "    class BeautifulSoup(bs4.element.Tag)\n",
      "     |  This class defines the basic interface called by the tree builders.\n",
      "     |  \n",
      "     |  These methods will be called by the parser:\n",
      "     |    reset()\n",
      "     |    feed(markup)\n",
      "     |  \n",
      "     |  The tree builder may call these methods from its feed() implementation:\n",
      "     |    handle_starttag(name, attrs) # See note about return value\n",
      "     |    handle_endtag(name)\n",
      "     |    handle_data(data) # Appends to the current data node\n",
      "     |    endData(containerClass=NavigableString) # Ends the current data node\n",
      "     |  \n",
      "     |  No matter how complicated the underlying parser is, you should be\n",
      "     |  able to build a tree using 'start tag' events, 'end tag' events,\n",
      "     |  'data' events, and \"done with data\" events.\n",
      "     |  \n",
      "     |  If you encounter an empty-element tag (aka a self-closing tag,\n",
      "     |  like HTML's <br> tag), call handle_starttag and then\n",
      "     |  handle_endtag.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BeautifulSoup\n",
      "     |      bs4.element.Tag\n",
      "     |      bs4.element.PageElement\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |      A copy of a Tag is a new Tag, unconnected to the parse tree.\n",
      "     |      Its contents are a copy of the old Tag's contents.\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self, markup='', features=None, builder=None, parse_only=None, from_encoding=None, exclude_encodings=None, **kwargs)\n",
      "     |      The Soup object is initialized as the 'root tag', and the\n",
      "     |      provided markup (which can be a string or a file-like object)\n",
      "     |      is fed into the underlying parser.\n",
      "     |  \n",
      "     |  decode(self, pretty_print=False, eventual_encoding='utf-8', formatter='minimal')\n",
      "     |      Returns a string or Unicode representation of this document.\n",
      "     |      To get Unicode, pass None for encoding.\n",
      "     |  \n",
      "     |  endData(self, containerClass=<class 'bs4.element.NavigableString'>)\n",
      "     |  \n",
      "     |  handle_data(self, data)\n",
      "     |  \n",
      "     |  handle_endtag(self, name, nsprefix=None)\n",
      "     |  \n",
      "     |  handle_starttag(self, name, namespace, nsprefix, attrs)\n",
      "     |      Push a start tag on to the stack.\n",
      "     |      \n",
      "     |      If this method returns None, the tag was rejected by the\n",
      "     |      SoupStrainer. You should proceed as if the tag had not occurred\n",
      "     |      in the document. For instance, if this was a self-closing tag,\n",
      "     |      don't call handle_endtag.\n",
      "     |  \n",
      "     |  insert_after(self, successor)\n",
      "     |      Makes the given element the immediate successor of this one.\n",
      "     |      \n",
      "     |      The two elements will have the same parent, and the given element\n",
      "     |      will be immediately after this one.\n",
      "     |  \n",
      "     |  insert_before(self, successor)\n",
      "     |      Makes the given element the immediate predecessor of this one.\n",
      "     |      \n",
      "     |      The two elements will have the same parent, and the given element\n",
      "     |      will be immediately before this one.\n",
      "     |  \n",
      "     |  new_string(self, s, subclass=<class 'bs4.element.NavigableString'>)\n",
      "     |      Create a new NavigableString associated with this soup.\n",
      "     |  \n",
      "     |  new_tag(self, name, namespace=None, nsprefix=None, **attrs)\n",
      "     |      Create a new tag associated with this soup.\n",
      "     |  \n",
      "     |  object_was_parsed(self, o, parent=None, most_recent_element=None)\n",
      "     |      Add an object to the parse tree.\n",
      "     |  \n",
      "     |  popTag(self)\n",
      "     |  \n",
      "     |  pushTag(self, tag)\n",
      "     |  \n",
      "     |  reset(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ASCII_SPACES = ' \\n\\t\\x0c\\r'\n",
      "     |  \n",
      "     |  DEFAULT_BUILDER_FEATURES = ['html', 'fast']\n",
      "     |  \n",
      "     |  NO_PARSER_SPECIFIED_WARNING = 'No parser was explicitly specified, so ...\n",
      "     |  \n",
      "     |  ROOT_TAG_NAME = '[document]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from bs4.element.Tag:\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      A tag is non-None even if it has no contents.\n",
      "     |  \n",
      "     |  __call__(self, *args, **kwargs)\n",
      "     |      Calling a tag like a function is the same as calling its\n",
      "     |      find_all() method. Eg. tag('a') returns a list of all the A tags\n",
      "     |      found within this tag.\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |      Deleting tag[key] deletes all 'key' attributes for the tag.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns true iff this tag has the same name, the same attributes,\n",
      "     |      and the same contents (recursively) as the given tag.\n",
      "     |  \n",
      "     |  __getattr__(self, tag)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      tag[key] returns the value of the 'key' attribute for the tag,\n",
      "     |      and throws an exception if it's not there.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Iterating over a tag iterates over its contents.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      The length of a tag is the length of its list of contents.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Returns true iff this tag is not identical to the other tag,\n",
      "     |      as defined in __eq__.\n",
      "     |  \n",
      "     |  __repr__ = __unicode__(self)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Setting tag[key] sets the value of the 'key' attribute for the\n",
      "     |      tag.\n",
      "     |  \n",
      "     |  __str__ = __unicode__(self)\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |  \n",
      "     |  childGenerator(self)\n",
      "     |      # Old names for backwards compatibility\n",
      "     |  \n",
      "     |  clear(self, decompose=False)\n",
      "     |      Extract all children. If decompose is True, decompose instead.\n",
      "     |  \n",
      "     |  decode_contents(self, indent_level=None, eventual_encoding='utf-8', formatter='minimal')\n",
      "     |      Renders the contents of this tag as a Unicode string.\n",
      "     |      \n",
      "     |      :param indent_level: Each line of the rendering will be\n",
      "     |         indented this many spaces.\n",
      "     |      \n",
      "     |      :param eventual_encoding: The tag is destined to be\n",
      "     |         encoded into this encoding. This method is _not_\n",
      "     |         responsible for performing that encoding. This information\n",
      "     |         is passed in so that it can be substituted in if the\n",
      "     |         document contains a <META> tag that mentions the document's\n",
      "     |         encoding.\n",
      "     |      \n",
      "     |      :param formatter: The output formatter responsible for converting\n",
      "     |         entities to Unicode characters.\n",
      "     |  \n",
      "     |  decompose(self)\n",
      "     |      Recursively destroys the contents of this tree.\n",
      "     |  \n",
      "     |  encode(self, encoding='utf-8', indent_level=None, formatter='minimal', errors='xmlcharrefreplace')\n",
      "     |  \n",
      "     |  encode_contents(self, indent_level=None, encoding='utf-8', formatter='minimal')\n",
      "     |      Renders the contents of this tag as a bytestring.\n",
      "     |      \n",
      "     |      :param indent_level: Each line of the rendering will be\n",
      "     |         indented this many spaces.\n",
      "     |      \n",
      "     |      :param eventual_encoding: The bytestring will be in this encoding.\n",
      "     |      \n",
      "     |      :param formatter: The output formatter responsible for converting\n",
      "     |         entities to Unicode characters.\n",
      "     |  \n",
      "     |  find(self, name=None, attrs={}, recursive=True, text=None, **kwargs)\n",
      "     |      Return only the first child of this Tag matching the given\n",
      "     |      criteria.\n",
      "     |  \n",
      "     |  findAll = find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)\n",
      "     |      Extracts a list of Tag objects that match the given\n",
      "     |      criteria.  You can specify the name of the Tag and any\n",
      "     |      attributes you want the Tag to have.\n",
      "     |      \n",
      "     |      The value of a key-value pair in the 'attrs' map can be a\n",
      "     |      string, a list of strings, a regular expression object, or a\n",
      "     |      callable that takes a string and returns whether or not the\n",
      "     |      string matches for some custom definition of 'matches'. The\n",
      "     |      same is true of the tag name.\n",
      "     |  \n",
      "     |  findChild = find(self, name=None, attrs={}, recursive=True, text=None, **kwargs)\n",
      "     |      Return only the first child of this Tag matching the given\n",
      "     |      criteria.\n",
      "     |  \n",
      "     |  findChildren = find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)\n",
      "     |      Extracts a list of Tag objects that match the given\n",
      "     |      criteria.  You can specify the name of the Tag and any\n",
      "     |      attributes you want the Tag to have.\n",
      "     |      \n",
      "     |      The value of a key-value pair in the 'attrs' map can be a\n",
      "     |      string, a list of strings, a regular expression object, or a\n",
      "     |      callable that takes a string and returns whether or not the\n",
      "     |      string matches for some custom definition of 'matches'. The\n",
      "     |      same is true of the tag name.\n",
      "     |  \n",
      "     |  find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)\n",
      "     |      Extracts a list of Tag objects that match the given\n",
      "     |      criteria.  You can specify the name of the Tag and any\n",
      "     |      attributes you want the Tag to have.\n",
      "     |      \n",
      "     |      The value of a key-value pair in the 'attrs' map can be a\n",
      "     |      string, a list of strings, a regular expression object, or a\n",
      "     |      callable that takes a string and returns whether or not the\n",
      "     |      string matches for some custom definition of 'matches'. The\n",
      "     |      same is true of the tag name.\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      Returns the value of the 'key' attribute for the tag, or\n",
      "     |      the value given for 'default' if it doesn't have that\n",
      "     |      attribute.\n",
      "     |  \n",
      "     |  getText = get_text(self, separator='', strip=False, types=(<class 'bs4.element.NavigableString'>, <class 'bs4.element.CData'>))\n",
      "     |      Get all child strings, concatenated using the given separator.\n",
      "     |  \n",
      "     |  get_attribute_list(self, key, default=None)\n",
      "     |      The same as get(), but always returns a list.\n",
      "     |  \n",
      "     |  get_text(self, separator='', strip=False, types=(<class 'bs4.element.NavigableString'>, <class 'bs4.element.CData'>))\n",
      "     |      Get all child strings, concatenated using the given separator.\n",
      "     |  \n",
      "     |  has_attr(self, key)\n",
      "     |  \n",
      "     |  has_key(self, key)\n",
      "     |      This was kind of misleading because has_key() (attributes)\n",
      "     |      was different from __in__ (contents). has_key() is gone in\n",
      "     |      Python 3, anyway.\n",
      "     |  \n",
      "     |  index(self, element)\n",
      "     |      Find the index of a child by identity, not value. Avoids issues with\n",
      "     |      tag.contents.index(element) getting the index of equal elements.\n",
      "     |  \n",
      "     |  prettify(self, encoding=None, formatter='minimal')\n",
      "     |  \n",
      "     |  recursiveChildGenerator(self)\n",
      "     |  \n",
      "     |  renderContents(self, encoding='utf-8', prettyPrint=False, indentLevel=0)\n",
      "     |      # Old method for BS3 compatibility\n",
      "     |  \n",
      "     |  select(self, selector, _candidate_generator=None, limit=None)\n",
      "     |      Perform a CSS selection operation on the current element.\n",
      "     |  \n",
      "     |  select_one(self, selector)\n",
      "     |      Perform a CSS selection operation on the current element.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from bs4.element.Tag:\n",
      "     |  \n",
      "     |  children\n",
      "     |  \n",
      "     |  descendants\n",
      "     |  \n",
      "     |  isSelfClosing\n",
      "     |      Is this tag an empty-element tag? (aka a self-closing tag)\n",
      "     |      \n",
      "     |      A tag that has contents is never an empty-element tag.\n",
      "     |      \n",
      "     |      A tag that has no contents may or may not be an empty-element\n",
      "     |      tag. It depends on the builder used to create the tag. If the\n",
      "     |      builder has a designated list of empty-element tags, then only\n",
      "     |      a tag whose name shows up in that list is considered an\n",
      "     |      empty-element tag.\n",
      "     |      \n",
      "     |      If the builder has no designated list of empty-element tags,\n",
      "     |      then any tag with no contents is an empty-element tag.\n",
      "     |  \n",
      "     |  is_empty_element\n",
      "     |      Is this tag an empty-element tag? (aka a self-closing tag)\n",
      "     |      \n",
      "     |      A tag that has contents is never an empty-element tag.\n",
      "     |      \n",
      "     |      A tag that has no contents may or may not be an empty-element\n",
      "     |      tag. It depends on the builder used to create the tag. If the\n",
      "     |      builder has a designated list of empty-element tags, then only\n",
      "     |      a tag whose name shows up in that list is considered an\n",
      "     |      empty-element tag.\n",
      "     |      \n",
      "     |      If the builder has no designated list of empty-element tags,\n",
      "     |      then any tag with no contents is an empty-element tag.\n",
      "     |  \n",
      "     |  parserClass\n",
      "     |  \n",
      "     |  string\n",
      "     |      Convenience property to get the single string within this tag.\n",
      "     |      \n",
      "     |      :Return: If this tag has a single string child, return value\n",
      "     |       is that string. If this tag has no children, or more than one\n",
      "     |       child, return value is None. If this tag has one child tag,\n",
      "     |       return value is the 'string' attribute of the child tag,\n",
      "     |       recursively.\n",
      "     |  \n",
      "     |  strings\n",
      "     |      Yield all strings of certain classes, possibly stripping them.\n",
      "     |      \n",
      "     |      By default, yields only NavigableString and CData objects. So\n",
      "     |      no comments, processing instructions, etc.\n",
      "     |  \n",
      "     |  stripped_strings\n",
      "     |  \n",
      "     |  text\n",
      "     |      Get all child strings, concatenated using the given separator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from bs4.element.Tag:\n",
      "     |  \n",
      "     |  quoted_colon = re.compile('\"[^\"]*:[^\"]*\"')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from bs4.element.PageElement:\n",
      "     |  \n",
      "     |  append(self, tag)\n",
      "     |      Appends the given tag to the contents of this tag.\n",
      "     |  \n",
      "     |  extract(self)\n",
      "     |      Destructively rips this element out of the tree.\n",
      "     |  \n",
      "     |  fetchNextSiblings = find_next_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Returns the siblings of this Tag that match the given\n",
      "     |      criteria and appear after this Tag in the document.\n",
      "     |  \n",
      "     |  fetchParents = find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      "     |      Returns the parents of this Tag that match the given\n",
      "     |      criteria.\n",
      "     |  \n",
      "     |  fetchPrevious = find_all_previous(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Returns all items that match the given criteria and appear\n",
      "     |      before this Tag in the document.\n",
      "     |  \n",
      "     |  fetchPreviousSiblings = find_previous_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Returns the siblings of this Tag that match the given\n",
      "     |      criteria and appear before this Tag in the document.\n",
      "     |  \n",
      "     |  findAllNext = find_all_next(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Returns all items that match the given criteria and appear\n",
      "     |      after this Tag in the document.\n",
      "     |  \n",
      "     |  findAllPrevious = find_all_previous(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Returns all items that match the given criteria and appear\n",
      "     |      before this Tag in the document.\n",
      "     |  \n",
      "     |  findNext = find_next(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |      Returns the first item that matches the given criteria and\n",
      "     |      appears after this Tag in the document.\n",
      "     |  \n",
      "     |  findNextSibling = find_next_sibling(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |      Returns the closest sibling to this Tag that matches the\n",
      "     |      given criteria and appears after this Tag in the document.\n",
      "     |  \n",
      "     |  findNextSiblings = find_next_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Returns the siblings of this Tag that match the given\n",
      "     |      criteria and appear after this Tag in the document.\n",
      "     |  \n",
      "     |  findParent = find_parent(self, name=None, attrs={}, **kwargs)\n",
      "     |      Returns the closest parent of this Tag that matches the given\n",
      "     |      criteria.\n",
      "     |  \n",
      "     |  findParents = find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      "     |      Returns the parents of this Tag that match the given\n",
      "     |      criteria.\n",
      "     |  \n",
      "     |  findPrevious = find_previous(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |      Returns the first item that matches the given criteria and\n",
      "     |      appears before this Tag in the document.\n",
      "     |  \n",
      "     |  findPreviousSibling = find_previous_sibling(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |      Returns the closest sibling to this Tag that matches the\n",
      "     |      given criteria and appears before this Tag in the document.\n",
      "     |  \n",
      "     |  findPreviousSiblings = find_previous_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Returns the siblings of this Tag that match the given\n",
      "     |      criteria and appear before this Tag in the document.\n",
      "     |  \n",
      "     |  find_all_next(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Returns all items that match the given criteria and appear\n",
      "     |      after this Tag in the document.\n",
      "     |  \n",
      "     |  find_all_previous(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Returns all items that match the given criteria and appear\n",
      "     |      before this Tag in the document.\n",
      "     |  \n",
      "     |  find_next(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |      Returns the first item that matches the given criteria and\n",
      "     |      appears after this Tag in the document.\n",
      "     |  \n",
      "     |  find_next_sibling(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |      Returns the closest sibling to this Tag that matches the\n",
      "     |      given criteria and appears after this Tag in the document.\n",
      "     |  \n",
      "     |  find_next_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Returns the siblings of this Tag that match the given\n",
      "     |      criteria and appear after this Tag in the document.\n",
      "     |  \n",
      "     |  find_parent(self, name=None, attrs={}, **kwargs)\n",
      "     |      Returns the closest parent of this Tag that matches the given\n",
      "     |      criteria.\n",
      "     |  \n",
      "     |  find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      "     |      Returns the parents of this Tag that match the given\n",
      "     |      criteria.\n",
      "     |  \n",
      "     |  find_previous(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |      Returns the first item that matches the given criteria and\n",
      "     |      appears before this Tag in the document.\n",
      "     |  \n",
      "     |  find_previous_sibling(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |      Returns the closest sibling to this Tag that matches the\n",
      "     |      given criteria and appears before this Tag in the document.\n",
      "     |  \n",
      "     |  find_previous_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Returns the siblings of this Tag that match the given\n",
      "     |      criteria and appear before this Tag in the document.\n",
      "     |  \n",
      "     |  format_string(self, s, formatter='minimal')\n",
      "     |      Format the given string using the given formatter.\n",
      "     |  \n",
      "     |  insert(self, position, new_child)\n",
      "     |  \n",
      "     |  nextGenerator(self)\n",
      "     |      # Old non-property versions of the generators, for backwards\n",
      "     |      # compatibility with BS3.\n",
      "     |  \n",
      "     |  nextSiblingGenerator(self)\n",
      "     |  \n",
      "     |  parentGenerator(self)\n",
      "     |  \n",
      "     |  previousGenerator(self)\n",
      "     |  \n",
      "     |  previousSiblingGenerator(self)\n",
      "     |  \n",
      "     |  replaceWith = replace_with(self, replace_with)\n",
      "     |  \n",
      "     |  replaceWithChildren = unwrap(self)\n",
      "     |  \n",
      "     |  replace_with(self, replace_with)\n",
      "     |  \n",
      "     |  replace_with_children = unwrap(self)\n",
      "     |  \n",
      "     |  setup(self, parent=None, previous_element=None, next_element=None, previous_sibling=None, next_sibling=None)\n",
      "     |      Sets up the initial relations between this element and\n",
      "     |      other elements.\n",
      "     |  \n",
      "     |  unwrap(self)\n",
      "     |  \n",
      "     |  wrap(self, wrap_inside)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from bs4.element.PageElement:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  next\n",
      "     |  \n",
      "     |  nextSibling\n",
      "     |  \n",
      "     |  next_elements\n",
      "     |  \n",
      "     |  next_siblings\n",
      "     |  \n",
      "     |  parents\n",
      "     |  \n",
      "     |  previous\n",
      "     |  \n",
      "     |  previousSibling\n",
      "     |  \n",
      "     |  previous_elements\n",
      "     |  \n",
      "     |  previous_siblings\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from bs4.element.PageElement:\n",
      "     |  \n",
      "     |  HTML_FORMATTERS = {'html': <bound method HTMLAwareEntitySubstitution.s...\n",
      "     |  \n",
      "     |  XML_FORMATTERS = {'html': <bound method EntitySubstitution.substitute_...\n",
      "     |  \n",
      "     |  attribselect_re = re.compile('^(?P<tag>[a-zA-Z0-9][-.a-zA-Z0-9:_]*...[...\n",
      "     |  \n",
      "     |  tag_name_re = re.compile('^[a-zA-Z0-9][-.a-zA-Z0-9:_]*$')\n",
      "\n",
      "DATA\n",
      "    __all__ = ['BeautifulSoup']\n",
      "    __copyright__ = 'Copyright (c) 2004-2017 Leonard Richardson'\n",
      "    __license__ = 'MIT'\n",
      "    __warningregistry__ = {'version': 225, ('No parser was explicitly spec...\n",
      "\n",
      "VERSION\n",
      "    4.6.0\n",
      "\n",
      "AUTHOR\n",
      "    Leonard Richardson (leonardr@segfault.org)\n",
      "\n",
      "FILE\n",
      "    c:\\workspace\\anaconda3\\lib\\site-packages\\bs4\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<title>The Dormouse's story</title>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.head.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Elsie ']\n"
     ]
    }
   ],
   "source": [
    "print(soup.a.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n"
     ]
    }
   ],
   "source": [
    "print(soup.head.contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<list_iterator object at 0x066CC630>\n"
     ]
    }
   ],
   "source": [
    "print(soup.head.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<p name=\"dromouse\"><b>The Dormouse's story</b></p>\n",
      "\n",
      "\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "\n",
      "\n",
      "<p class=\"story\">...</p>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for child in soup.body.children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head><title>The Dormouse's story</title></head>\n",
      "<body>\n",
      "<p name=\"dromouse\"><b>The Dormouse's story</b></p>\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "<p class=\"story\">...</p>\n",
      "</body></html>\n",
      "<head><title>The Dormouse's story</title></head>\n",
      "<title>The Dormouse's story</title>\n",
      "The Dormouse's story\n",
      "\n",
      "\n",
      "<body>\n",
      "<p name=\"dromouse\"><b>The Dormouse's story</b></p>\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "<p class=\"story\">...</p>\n",
      "</body>\n",
      "\n",
      "\n",
      "<p name=\"dromouse\"><b>The Dormouse's story</b></p>\n",
      "<b>The Dormouse's story</b>\n",
      "The Dormouse's story\n",
      "\n",
      "\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "Once upon a time there were three little sisters; and their names were\n",
      "\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>\n",
      " Elsie \n",
      ",\n",
      "\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "Lacie\n",
      " and\n",
      "\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "Tillie\n",
      ";\n",
      "and they lived at the bottom of a well.\n",
      "\n",
      "\n",
      "<p class=\"story\">...</p>\n",
      "...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for child in soup.descendants:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "for tag in soup.find_all(re.compile('^b')):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>The Dormouse's story</b>,\n",
       " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(['a','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html\n",
      "head\n",
      "title\n",
      "body\n",
      "p\n",
      "b\n",
      "p\n",
      "a\n",
      "a\n",
      "a\n",
      "p\n"
     ]
    }
   ],
   "source": [
    "for tag in soup.find_all(True):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_class_but_no_id(tag):\n",
    "    return tag.has_attr('class') and not tag.has_attr('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       " and they lived at the bottom of a well.</p>, <p class=\"story\">...</p>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(has_class_but_no_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('https://book.douban.com/subject/6082808/comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parrten = soup.find_all('p','comment-content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parrten = soup.find_all(class_=\"comment-content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个人都是孤独地出生，在这世间恍惚几十年并不漫长的日子转眼就远去了，然后再孤独地死去。 生命注定是个悲剧，因为我们从没有融入世界，世界永远是身外之物。如果有幸，能在茫茫人海寻得一个身体与灵魂都与自己万分契合的人，与之存在一种可以称之为爱情的联系，然后一起承受生命中不可逃离不可消除的深沉的宿命的孤独。可是这般的幸运艰深难得。有的已失去了爱的能力，有的爱的深沉却无处安放，有的死在这爱里……在所有的爱里，孤独有增无减。  生命只是一场幻梦。\n",
      "看第3遍开始越来越让我惊艳的已不是马尔克斯而是译者了。太牛逼了！这样的文字就算是母语创作也属上乘。尤其倒数第二代布恩迪亚在飓风中破译羊皮卷的全书结尾，笔触磅礴，美到让人惊怖。\n",
      "为什么我觉得不好看呢？是不是我没文化看不懂啊！\n",
      "14年间中文读过5遍以上，英文两遍，被水银泻地般的语言携裹到终章时，内心的激动依然不可抑制。那感觉仿佛是亲手将一件精美而无价的珍宝摔碎在地，带着一种秘密的，幸福的震颤 \n",
      "开始很吃力，越读越上瘾。 惊人得叙事与潮水版的叙事，野兽般撕开真理得外衣。  原来那句经典的开场白，源自这本书。从四姑娘的第一本书，也就开始了他的抄袭生涯。\n",
      "一口气读完但却没有能力评价。\n",
      "“奥雷里亚诺，”他悲伤地敲下发报键，“马孔多在下雨。”\n",
      "一个家族百年反复浮现的竟然就那么几个名字，加西亚真的很残酷。一代又一代就像被推上命运轮盘赌后不断开出的绝望点数，以致于在最后血脉断绝的一刻，我们感到的不是同情而是如释重负。然而家族可以终结，孤独却是无视时空的永恒存在。它从洪荒流淌至今，还将延绵万世，就像南美大陆奔腾壮丽的亚马逊河，碾碎一切人事物。\n",
      "多年以后，面对 iPhone9，正在发送朋友圈的我将会想起独自一人阅读羊皮卷的那个遥远的夜晚。那时的我坐在书桌前，以几乎不动的姿势一页页的翻阅，眼前的文字在昏暗的灯光下像水一样流过。不可思议的是，沉浸在这由难以承受的痛苦和无法摆脱的孤独构成的故事中时，我竟然涌起了类似于平静恬然的情绪，那是一种比夜晚幽会中疯狂而短暂的快乐更平和深沉的感觉。就好像我知道人终究会老去，但在阳光打到脸上的瞬间，仍然忍不住微笑。\n",
      "家族谱太混乱，刚看的时候觉得：这么丧尸居然能是名著。看完以后觉得：这么丧尸不是名著太他妈浪费了...\n",
      "我的睡前读物，确实起到了很好的催眠效果，每当我纠缠于这个奥雷利亚诺是哪个奥雷利亚诺的时候就倦意袭来倒头就睡。前半本的时候还勉强能搞清楚他们家的复杂关系，后来就彻底放弃了，我已经不在乎角色之间的关系，就专注于情节好了，WELL，一些隐喻呀之类的还算看明白了。但我真是烦啊……他们家人搞得神奇的过得苦的，特别是乌尔苏拉。\n",
      "一开始我还为华丽的辞藻，荒诞的情节，冗长的姓氏感到烦躁不堪。。。但随着故事的深入展开，我才发现我错了。。。那么繁复的一大家庭，七代人的辉煌与落寞，激情与孤独，坚毅与懒惰，世俗与超脱，疯狂与冷静。。。就这样蔓延开来。。叫人感慨的同时不禁也要叹惜一下。。孤独的何止是百年。。\n",
      "伟大的小说便是这样，倾注了作者全部的精神和价值重塑一个世界。而人物、情节、文笔、风格不过是帮助组织架构这伟大工程的工具。原来以为会读不下去，但一开页则根本停不下来。翻译也很加分。\n",
      "回忆没有归路，春天总是一去不返。车窗外瞬间闪过世间万象，如同将一首飞逝的长诗撕成碎片向着遗忘之乡一路抛洒。\n",
      "大学时草草看过，这次是第二遍，顺带自制一张布恩迪亚家族谱。这本书的神奇之处在于，看完像是活了一世纪之久，一个人。\n",
      "庆幸是在我22岁的时候读到，没有太晚\n",
      "令人恐惧的伟大小说。无法摆脱的孤独与无力，梦想与激情皆成泡影，暴风之中，只剩回忆。\n",
      "家族的第一个人被捆在树上，最后一个人正被蚂蚁吃掉。\n",
      "现在这才算是真正的读过。删了之前的短评却又不知道该写些什么。不过作者应该是很钟意不加糖的咖啡，我看过他的每本书里至少都有一个人有这种嗜好。《百》和《霍》绝对称得上是名著，也是我目前为止看到的唯一的作者还活着的世界级名著。\n",
      "费尔南达真他妈烦人\n"
     ]
    }
   ],
   "source": [
    "for item in parrten:\n",
    "    print(item.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950 20\n"
     ]
    }
   ],
   "source": [
    "parrten_s = '<span class=\"user-stars allstar(.*?) rating\"'\n",
    "p = re.findall(parrten_s, r.text)\n",
    "sum = 0\n",
    "count = 0\n",
    "for item in p:\n",
    "    sum += int(item)\n",
    "    count += 1\n",
    "print(sum,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m                     \u001b[1;31m# otherwise it looks like a programming error was the cause.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    381\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1330\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1331\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1332\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m                 )\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    648\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 649\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    650\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m                     \u001b[1;31m# otherwise it looks like a programming error was the cause.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    381\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1330\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1331\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1332\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-daacb0857006>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://money.cnn.com/data/dow30/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    516\u001b[0m         }\n\u001b[0;32m    517\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\workspace\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))"
     ]
    }
   ],
   "source": [
    "r = requests.get('http://money.cnn.com/data/dow30/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "r = requests.get('https://book.douban.com/subject/6082808/comments/hot?p'+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-48c78e56e06d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'reload' is not defined"
     ]
    }
   ],
   "source": [
    "help(reload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-122-df5c87bf68be>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-122-df5c87bf68be>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    import ex3-1\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import ex3-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp    price    code\n",
      "MMM   203.56    1,413,014 \n",
      "AXP   86.14     2,262,735 \n",
      "AAPL  164.05    16,591,051\n",
      "BA    240.33    3,271,270 \n",
      "CAT   118.28    2,992,226 \n",
      "CVX   108.76    3,660,250 \n",
      "CSCO  32.30     14,686,578\n",
      "KO    45.78     7,391,249 \n",
      "DIS   101.50    7,827,433 \n",
      "XOM   76.57     7,361,092 \n",
      "GE    25.14     58,848,107\n",
      "GS    225.88    2,346,855 \n",
      "HD    150.78    3,383,036 \n",
      "IBM   144.08    3,351,733 \n",
      "INTC  35.09     12,821,972\n",
      "JNJ   131.03    3,820,814 \n",
      "JPM   91.70     9,815,834 \n",
      "MCD   159.81    1,878,291 \n",
      "MRK   63.83     6,185,056 \n",
      "MSFT  73.94     21,736,161\n",
      "NKE   53.36     5,509,805 \n",
      "PFE   33.96     18,179,055\n",
      "PG    92.53     4,960,653 \n",
      "TRV   119.90    1,547,044 \n",
      "UTX   117.92    2,644,747 \n",
      "UNH   199.75    2,242,195 \n",
      "VZ    47.92     11,455,202\n",
      "V     103.90    4,466,772 \n",
      "WMT   78.37     6,474,360 \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
